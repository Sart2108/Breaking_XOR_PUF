{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0fb8209a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# This is the only scipy method you are allowed to use\n",
    "# Use of scipy is not allowed otherwise\n",
    "from scipy.linalg import khatri_rao\n",
    "import random as rnd\n",
    "import time as tm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bf581590",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_renamed_labels( y ):\n",
    "################################\n",
    "#  Non Editable Region Ending  #\n",
    "################################\n",
    "\n",
    "\t# Since the dataset contain 0/1 labels and SVMs prefer -1/+1 labels,\n",
    "\t# Decide here how you want to rename the labels\n",
    "\t# For example, you may map 1 -> 1 and 0 -> -1 or else you may want to go with 1 -> -1 and 0 -> 1\n",
    "\t# Use whatever convention you seem fit but use the same mapping throughout your code\n",
    "\t# If you use one mapping for train and another for test, you will get poor accuracy\n",
    "\ty_new = 2 * y -1\n",
    "\treturn y_new.reshape( ( y_new.size, ) )\t\t\t\t\t# Reshape y_new as a vector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5ae91e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features( X ):\n",
    "################################\n",
    "#  Non Editable Region Ending  #\n",
    "################################\n",
    "\n",
    "\t# Use this function to transform your input features (that are 0/1 valued)\n",
    "\t# into new features that can be fed into a linear model to solve the problem\n",
    "\t# Your new features may have a different dimensionality than the input features\n",
    "\t# For example, in this application, X will be 8 dimensional but your new\n",
    "\t# features can be 2 dimensional, 10 dimensional, 1000 dimensional, 123456 dimensional etc\n",
    "\t# Keep in mind that the more dimensions you use, the slower will be your solver too\n",
    "\t# so use only as many dimensions as are absolutely required to solve the problem\n",
    "\tX =  np.cumprod( np.flip( 2 * X - 1 , axis = 1 ), axis = 1 )\n",
    "\tX = np.c_[X,np.ones(X.shape[0])]\n",
    "\ta=np.transpose(X)\n",
    "\tb=khatri_rao(a,a)\n",
    "\tX=np.transpose(khatri_rao(a,b))\n",
    "        \n",
    "\t#return np.array(Vector_list)\n",
    "\treturn X\n",
    "  \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "################################\n",
    "# Non Editable Region Starting #\n",
    "################################\n",
    "def solver( X, y, timeout, spacing ):\n",
    "\t(n, d) = X.shape\n",
    "\tt = 0\n",
    "\ttotTime = 0\n",
    "\t\n",
    "\t# W is the model vector and will get returned once timeout happens\n",
    "\t# B is the bias term that will get returned once timeout happens\n",
    "\t# The bias term is optional. If you feel you do not need a bias term at all, just keep it set to 0\n",
    "\t# However, if you do end up using a bias term, you are allowed to internally use a model vector\n",
    "\t# that hides the bias inside the model vector e.g. by defining a new variable such as\n",
    "\t# W_extended = np.concatenate( ( W, [B] ) )\n",
    "\t# However, you must maintain W and B variables separately as well so that they can get\n",
    "\t# returned when timeout happens. Take care to update W, B whenever you update your W_extended\n",
    "\t# variable otherwise you will get wrong results.\n",
    "\t# Also note that the dimensionality of W may be larger or smaller than 9\n",
    "\t\n",
    "\tW = []\n",
    "\tB = 0\n",
    "\ttic = tm.perf_counter()\n",
    "################################\n",
    "#  Non Editable Region Ending  #\n",
    "################################\n",
    "\n",
    "\tX = get_features(X)\n",
    "\ty = get_renamed_labels(y)\n",
    "\tW = np.zeros(729)\n",
    "\tlearning = 0.005\n",
    "\tlamba = 0.001\n",
    "\t# You may reinitialize W, B to your liking here e.g. set W to its correct dimensionality\n",
    "\t# You may also define new variables here e.g. step_length, mini-batch size etc\n",
    "################################\n",
    "# Non Editable Region Starting #\n",
    "################################\n",
    "\twhile True:\n",
    "\t\tt = t + 1\n",
    "\t\tif t % spacing == 0:\n",
    "\t\t\ttoc = tm.perf_counter()\n",
    "\t\t\ttotTime = totTime + (toc - tic)\n",
    "\t\t\tif totTime > timeout:\n",
    "\t\t\t\treturn ( W.reshape( ( W.size, ) ), B, totTime )\t\t\t# Reshape W as a vector\n",
    "\t\t\telse:\n",
    "\t\t\t\ttic = tm.perf_counter()\n",
    "################################\n",
    "#  Non Editable Region Ending  #\n",
    "################################\n",
    "\n",
    "\t\tr2 = rnd.randint(1,X.shape[0]-1)\n",
    "\t\tcheck = y[r2]* np.dot(X[r2],W)\n",
    "\t\tif check >= 1:\n",
    "\t\t\tW -= learning * (lamba)\n",
    "\t\telse:\n",
    "\t\t\tW -= learning * ( lamba * W - y[r2]*X[r2])\n",
    "\treturn ( W.reshape( ( W.size, ) ), B, totTime )\n",
    "    \n",
    "\n",
    "\t\n",
    "\n",
    "\t\n",
    "\n",
    "\t\n",
    "\t\t# Write all code to perform your method updates here within the infinite while loop\n",
    "\t\t# The infinite loop will terminate once timeout is reached\n",
    "\t\t# Do not try to bypass the timer check e.g. by using continue\n",
    "\t\t# It is very easy for us to detect such bypasses which will be strictly penalized\n",
    "\t\t\n",
    "\t\t# Note that most likely, you should be using get_features( X ) and get_renamed_labels( y )\n",
    "\t\t# in this part of the code instead of X and y -- please take care\n",
    "\t\t\n",
    "\t\t# Please note that once timeout is reached, the code will simply return W, B\n",
    "\t\t# Thus, if you wish to return the average model (as is sometimes done for GD),\n",
    "\t\t# you need to make sure that W, B store the averages at all times\n",
    "\t\t# One way to do so is to define a \"running\" variable w_run, b_run\n",
    "\t\t# Make all GD updates to W_run e.g. W_run = W_run - step * delW (similarly for B_run)\n",
    "\t\t# Then use a running average formula to update W (similarly for B)\n",
    "\t\t# W = (W * (t-1) + W_run)/t\n",
    "\t\t# This way, W, B will always store the averages and can be returned at any time\n",
    "\t\t# In this scheme, W, B play the role of the \"cumulative\" variables in the course module optLib (see the cs771 library)\n",
    "\t\t# W_run, B_run on the other hand, play the role of the \"theta\" variable in the course module optLib (see the cs771 library) \n",
    "\t\t# This return statement will never be reached"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "92a42919",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttimeout = 0.2\n",
      "\t\tTrial 1 of 5\n",
      "\t\tTrial 2 of 5\n",
      "\t\tTrial 3 of 5\n",
      "\t\tTrial 4 of 5\n",
      "\t\tTrial 5 of 5\n",
      "\ttimeout = 0.5\n",
      "\t\tTrial 1 of 5\n",
      "\t\tTrial 2 of 5\n",
      "\t\tTrial 3 of 5\n",
      "\t\tTrial 4 of 5\n",
      "\t\tTrial 5 of 5\n",
      "\ttimeout = 1.0\n",
      "\t\tTrial 1 of 5\n",
      "\t\tTrial 2 of 5\n",
      "\t\tTrial 3 of 5\n",
      "\t\tTrial 4 of 5\n",
      "\t\tTrial 5 of 5\n",
      "\ttimeout = 2.0\n",
      "\t\tTrial 1 of 5\n",
      "\t\tTrial 2 of 5\n",
      "\t\tTrial 3 of 5\n",
      "\t\tTrial 4 of 5\n",
      "\t\tTrial 5 of 5\n",
      "\ttimeout = 5.0\n",
      "\t\tTrial 1 of 5\n",
      "\t\tTrial 2 of 5\n",
      "\t\tTrial 3 of 5\n",
      "\t\tTrial 4 of 5\n",
      "\t\tTrial 5 of 5\n"
     ]
    }
   ],
   "source": [
    "#Eval\n",
    "import numpy as np\n",
    "from submit import get_renamed_labels\n",
    "from submit import solver\n",
    "from submit import get_features\n",
    "import time as tm\n",
    "\n",
    "# Find out how much hinge loss the learnt model incurre\n",
    "def get_hinge_loss( X, y, w, b ):\n",
    "\tXX = get_features( X )\n",
    "\tscores = XX.dot( w ) + b\n",
    "\thinge_loss = 1 - np.multiply( scores, get_renamed_labels( y ) )\n",
    "\thinge_loss[ hinge_loss < 0 ] = 0\n",
    "\treturn np.average( hinge_loss )\n",
    "\n",
    "# Find out the misclassification error rate of the model\n",
    "def get_misclassification_rate( X, y, w, b ):\n",
    "\tXX = get_features( X )\n",
    "\tscores = XX.dot( w ) + b\n",
    "\tpredictions = np.ones_like( scores )\n",
    "\tpredictions[ scores < 0 ] = -1\n",
    "\treturn 1 - np.average( get_renamed_labels( y ) == predictions )\n",
    "\n",
    "Z_trn = np.loadtxt( \"secret_train.dat\" )\n",
    "Z_tst = np.loadtxt( \"secret_test.dat\" )\n",
    "\n",
    "# To avoid unlucky outcomes try running the code several times\n",
    "num_trials = 5\n",
    "\n",
    "# Try various timeouts - the timeouts are in seconds\n",
    "timeouts = np.array( [ 0.2, 0.5, 1, 2, 5 ] )\n",
    "\n",
    "# Try checking for timeout every 10 iterations\n",
    "spacing = 10\n",
    "\n",
    "result = np.zeros( ( len( timeouts ), 4 ) )\n",
    "\n",
    "for i in range( len( timeouts ) ):\n",
    "\tto = timeouts[i]\n",
    "\tprint( \"\\ttimeout =\", to )\n",
    "\tavg_hinge = 0\n",
    "\tavg_error = 0\n",
    "\tavg_time_reported = 0\n",
    "\tavg_time_wrapper = 0\n",
    "\tfor t in range( num_trials ):\n",
    "\t\tprint( \"\\t\\tTrial %d of %d\" % ( t + 1, num_trials ) )\n",
    "\t\ttic = tm.perf_counter()\n",
    "\t\t( w, b, totTime ) = solver( Z_trn[:,:-1], Z_trn[:,-1], to, spacing )\n",
    "\t\ttoc = tm.perf_counter()\n",
    "\t\tavg_hinge += get_hinge_loss( Z_tst[:,:-1], Z_tst[:,-1], w, b )\n",
    "\t\tavg_error += get_misclassification_rate( Z_tst[:,:-1], Z_tst[:,-1], w, b )\n",
    "\t\tavg_time_reported += totTime\n",
    "\t\tavg_time_wrapper += toc - tic\n",
    "\tresult[i, 0] = avg_hinge/num_trials\n",
    "\tresult[i, 1] = avg_error/num_trials\n",
    "\tresult[i, 2] = avg_time_reported/num_trials\n",
    "\tresult[i, 3] = avg_time_wrapper/num_trials\n",
    "\n",
    "np.savetxt( \"result\", result, fmt = \"%.6f\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf3905e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60fcac0b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
